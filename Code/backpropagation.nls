extensions [ table ]

globals 
[
  epoch-error
  validation-error
  test-error
  stop-criteria-met
]

to backpropagation-train [ data n-hidden-layers ]
  
  let af get-af
  let daf get-daf
 
  let cross-validation-datasets ( split-for-cross-validation data )
  
  set epoch-error 0
  set validation-error 0
  set test-error 0
  
  let training-set item 0 cross-validation-datasets
  let validation-set item 1 cross-validation-datasets
  let test-set item 2 cross-validation-datasets
  
  train training-set af daf n-hidden-layers
  
  validate validation-set af n-hidden-layers
  
  test test-set af n-hidden-layers
  
  recolor
  
  tick
  
end

to propagate [ af n-hidden-layers ]
  
  foreach ( n-values n-hidden-layers [?] )
  [
    ask hidden-nodes with [ layer = ? ]
    [
      set local-field induced-local-field
      set activation ( runresult af local-field )
    ]
  ]
  
  ask output-nodes 
  [
    set local-field induced-local-field
    set activation ( runresult af local-field )
  ]
  
end

to validate [ validation-set af num-h-layers ]
  
  foreach validation-set 
  [
    let input-data ( item 0 ? )
    let out-data ( item 1 ? )
    
    activate-inputs input-data
    
    propagate af num-h-layers
    
    calc-output-nodes-error out-data
    
    set validation-error ( validation-error + sum [ err ^ 2 ] of output-nodes )
  ]
  
  set validation-error ( 1 / ( 2 * length validation-set ) ) * validation-error
  
end

to test [ test-set af num-h-layers ]
  
  foreach test-set 
  [
    let input-data ( item 0 ? )
    let out-data ( item 1 ? )
    
    activate-inputs input-data
    
    propagate af num-h-layers
    
    calc-output-nodes-error out-data
    
    set test-error ( test-error + sum [ err ^ 2 ] of output-nodes )
  ]
  
  set test-error ( 1 / ( 2 * length test-set ) ) * test-error
  
end

to train [ training-set af daf n-hidden-layers ]
  
  foreach training-set 
  [
    ; pair of input-data and out-data is array
    ; input-data -> array
    ; out-data -> array
    let input-data ( item 0 ? )
    let out-data ( item 1 ? )
    
    activate-inputs input-data
    
    propagate af n-hidden-layers
    
    calc-output-nodes-error out-data
    
    ifelse ( training-algorithm = "back-propagate" )
    [
      back-propagate daf n-hidden-layers
    ]
    [
      back-propagate-haykin daf n-hidden-layers
    ]
    
    set epoch-error ( epoch-error + sum [ err ^ 2 ] of output-nodes )
  ]
  
  set epoch-error ( 1 / ( 2 * length training-set ) ) * epoch-error
  
end

to back-propagate [ daf n-hidden-layers ]
  
  ask output-nodes 
  [
    set local-gradient err * ( runresult daf activation )
  ]
  
  foreach ( reverse n-values n-hidden-layers [?] )
  [
    ask hidden-nodes with [ layer = ? ]
    [
      set local-gradient ( runresult daf activation ) * sum [ weight * [local-gradient] of end2 ] of my-out-links
    ]
  ]
  
  ask links with [ link-type = connection-link-type ]
  [
    set velocity momentum * velocity + learning-rate * [ activation ] of end1 * [ local-gradient ] of end2
    set weight weight + velocity
  ]
  
end


to back-propagate-haykin [ daf n-hidden-layers ]
  
  ask output-nodes 
  [
    set local-gradient err * ( runresult daf activation )
    
    ask my-in-links
    [
      set velocity ( momentum * velocity + learning-rate * [ activation ] of end1 * [ local-gradient ] of end2 )
      set weight weight + velocity
    ]
  ]
  
  foreach ( reverse n-values n-hidden-layers [?] )
  [
    ask hidden-nodes with [ layer = ? ]
    [
      set local-gradient ( runresult daf activation ) * sum [ weight * [ local-gradient ] of end2 ] of my-out-links
      
      ask my-in-links
      [
        set velocity ( momentum * velocity + learning-rate * [ activation ] of end1 * [ local-gradient ] of end2 )
        set weight weight + velocity
      ]
    ]
  ]
  
end